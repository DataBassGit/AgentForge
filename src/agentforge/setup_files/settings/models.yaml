# Default model settings for all agents unless overridden 
default_model: 
  api: gemini_api 
  model: gemini_flash 
# Example of using alternative default models 
#  api: lm_studio_api 
#  model: LMStudio 
#  api: openai_api 
#  model: omni_model 
 
# Library of models and parameter defaults 
model_library: 
  openai_api:  # API script name 
    O1Series:  # Class name for the API (Case Sensitive) 
      models:  # List of model configurations 
        o1: 
          identifier: o1 
          params: {}  # No overrides for this model 
        o1_preview: 
          identifier: o1-preview 
        o1_mini: 
          identifier: o1-mini 
        o4-mini:
          identifier: o4-mini 
        o3: 
          identifier: o3 
        o3-mini: 
          identifier: o3-mini 
 
      params: {}  # Default parameters for the model class 
 
    GPT: 
      models: 
        omni_model: 
          identifier: gpt-4o 
          params: 
            max_tokens: 15000  # Example of overriding parameters 
        smart_model: 
          identifier: gpt-4 
        smart_fast_model: 
          identifier: gpt-4-turbo 
        fast_model: 
          identifier: gpt-3.5-turbo 
        gpt41_model: 
          identifier: gpt-4.1 
          params: 
            max_tokens: 100000  # 1M token context window (max output set to 100k) 
 
      params:  # Default parameters for GPT models 
        max_tokens: 10000 
        n: 1 
        presence_penalty: 0 
        stop: null 
        temperature: 0.8 
        top_p: 0.1 
 
  anthropic_api: 
    Claude: 
      models: 
        claude3opus: 
          identifier: claude-3-opus-20240229 
        claude4opus: 
          identifier: claude-opus-4-20250514 
        claude4sonnet: 
          identifier: claude-sonnet-4-20250514 
        claude3.7sonnet: 
          identifier: claude-3-7-sonnet-latest 
        claude3.7haiku: 
          identifier: claude-3-5-haiku-latest 
 
      params:  # Default parameters for Claude models 
        max_tokens: 10000 
        temperature: 0.8 
        top_p: 0.1 
 
  gemini_api: 
    Gemini: 
      models: 
        gemini_pro: 
          identifier: gemini-2.5-pro-preview-05-06 
        gemini_flash: 
          identifier: gemini-2.5-flash-preview-04-17 
 
      params:  # Default parameters for Gemini models 
        candidate_count: 1 
        max_output_tokens: 10000 
        temperature: 0.8 
        top_k: 40 
        top_p: 0.1 
 
  lm_studio_api: 
    LMStudio: 
      models: 
        llama3_8b: 
          identifier: lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF 
 
      params:  # Default parameters for LMStudio models 
        host_url: http://localhost:1234/v1/chat/completions 
        max_tokens: 10000 
        stream: false 
        temperature: 0.8 
 
  ollama_api: 
    Ollama: 
      models: 
        llama3.1_70b: 
          identifier: llama3.1:70b 
 
      params:  # Default parameters for Ollama models 
        host_url: http://localhost:11434/api/generate 
        max_tokens: 10000 
        stream: false 
        temperature: 0.8 
 
  openrouter_api: 
    OpenRouter: 
      models: 
        phi3med: 
          identifier: microsoft/phi-3-medium-128k-instruct:free 
        hermes: 
          identifier: nousresearch/hermes-3-llama-3.1-405b 
        reflection: 
          identifier: mattshumer/reflection-70b:free 
 
  groq_api: 
    GroqAPI: 
      models: 
        llama31: 
          identifier: llama-3.3-70b-versatile 
 
      params:  # Default parameters for GroqAPI models 
        max_tokens: 10000 
        seed: -1 
        stop: null 
        temperature: 0.8 
        top_p: 0.1 
 
# Embedding library 
embedding_library: 
  library: sentence_transformers 
