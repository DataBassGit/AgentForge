# Default settings for all models unless overridden
ModelSettings:
  API: openai_api
  Model: omni_model
#  API: lm_studio_api
#  Model: LMStudio
  Params: # Default parameter values
    max_new_tokens: 3000
    temperature: 0.8
    top_p: 0.1
    n: 1
    stop: null
    do_sample: true
    return_prompt: false
    return_metadata: false
    typical_p: 0.95
    repetition_penalty: 1.05
    encoder_repetition_penalty: 1.0
    top_k: 40
    min_length: 10
    no_repeat_ngram_size: 0
    num_beams: 1
    penalty_alpha: 0
    length_penalty: 1
    early_stopping: false
    pad_token_id: null
    eos_token_id: null
    use_cache: true
    num_return_sequences: 1
    bad_words_ids: null
    seed: -1

# Library of Models and Parameter Defaults Override
ModelLibrary:
  openai_api:
    module: "openai"
    class: "GPT"
    models:
      omni_model:
        name: gpt-4o
        params: # Specific parameters for the model
          max_new_tokens: 3500
      smart_model:
        name: gpt-4
      smart_fast_model:
        name: gpt-4-turbo-2024-04-09
      fast_model:
        name: gpt-3.5-turbo
      long_fast_model:
        name: gpt-3.5-turbo-16k
      old_fast_model:
        name: gpt-3.5-turbo-0613
      old_long_fast_model:
        name: gpt-3.5-turbo-16k-0613
  groq_api:
    module: "groq_api"
    class: "GroqAPI"
    models:
      llama31:
        name: llama-3.1-70b-versatile
  openrouter_api:
    module: "openrouter"
    class: "OpenRouter"
    models:
      phi3med:
        name: microsoft/phi-3-medium-128k-instruct:free
      hermes:
        name: nousresearch/hermes-3-llama-3.1-405b
      reflection:
        name: mattshumer/reflection-70b:free
  claude_old:
    module: "claude_old"
    class: "Claude"
    models:
      claude:
        name: claude-2
  claude3_api:
    module: "anthropic"
    class: "Claude"
    models:
      claude-3:
        name: claude-3-opus-20240229
  gemini_api:
    module: "gemini"
    class: "Gemini"
    models:
      gemini-pro:
        name: gemini-1.5-pro
      gemini-flash:
        name: gemini-1.5-flash
  lm_studio_api:
    module: "LMStudio"
    class: "LMStudio"
    models:
      LMStudio:
        name: lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF
        params:
          host_url: "http://localhost:1234/v1/chat/completions"
          allow_custom_value: True
  ollama_api:
    module: "ollama"
    class: "Ollama"
    models:
      Llama3.1_70b:
        name: "llama3.1:70b"
        params:
          host_url: "http://localhost:11434/api/generate"
          allow_custom_value: True

# Embedding Library (Not much to see here)
EmbeddingLibrary:
  library: sentence_transformers
