# Default model for all agents unless overridden
Selected Model:
  API: gemini_api
  Model: gemini_flash
#  API: lm_studio_api
#  Model: LMStudio
#  API: openai_api
#  Model: omni_model
#  Model: o1_preview

# Library of Models and Parameter Defaults Override
Model Library:
  openai_api: # name of the respective api script
    O1Series: # Name of the Class for the api
      models: # List of model configurations
        o1:   # Model name for selection referencing
          identifier: o1 # model identifier expected by the API
          params: # model parameter overrides
        o1_preview:
          identifier: o1-preview
        o1_mini:
          identifier: o1-mini

      params: # Default model parameters for a model class may nor exist or be left empty without issues

    GPT:
      models:
        omni_model:
          identifier: gpt-4o
          params: # Example of overriding default model parameters for a singular model configuration
            max_new_tokens: 15000

        smart_model:
          identifier: gpt-4

        smart_fast_model:
          identifier: gpt-4-turbo

        fast_model:
          identifier: gpt-3.5-turbo

      params: # Example of model parameters for GPT class
        max_tokens: 10000
        n: 1
        presence_penalty: 0
        stop: null
        temperature: 0.8
        top_p: 0.1

  anthropic_api:
    Claude:
      models:
        claude3:
          identifier: claude-3-opus-20240229

    params:
      max_tokens: 10000
      temperature: 0.8
      top_p: 0.1

  gemini_api:
    Gemini:
      models:
        gemini_pro:
          identifier: gemini-1.5-pro
        gemini_flash:
          identifier: gemini-1.5-flash

      params:
        candidate_count: 1
        max_output_tokens: 10000
        temperature: 0.8
        top_k: 40
        top_p: 0.1

  lm_studio_api:
    LMStudio:
      models:
        Llama3_8B:
          identifier: lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF

      params:
        host_url: http://localhost:1234/v1/chat/completions
        max_tokens: 10000
        stream: false
        temperature: 0.8

  ollama_api:
    Ollama:
      models:
        Llama3.1_70b:
          identifier: llama3.1:70b

      params:
        host_url: http://localhost:11434/api/generate
        max_tokens: 10000
        stream: false
        temperature: 0.8

  openrouter_api:
    OpenRouter:
      models:
        phi3med:
          identifier: microsoft/phi-3-medium-128k-instruct:free
        hermes:
          identifier: nousresearch/hermes-3-llama-3.1-405b
        reflection:
          identifier: mattshumer/reflection-70b:free

  groq_api:
    GroqAPI:
      models:
        llama31:
          identifier: llama-3.1-70b-versatile

      params:
        max_tokens: 10000
        seed: -1
        stop: null
        temperature: 0.8
        top_p: 0.1

# Embedding Library (Not much to see here)
Embedding Library:
  library: sentence_transformers
