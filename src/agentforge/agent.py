# agent.py

from typing import Any, Dict, Optional, List

from .config import Config
from agentforge.apis.base_api import BaseModel
from agentforge.utils.logger import Logger
from agentforge.utils.prompt_processor import PromptProcessor


class Agent:
    def __init__(self, agent_name: Optional[str] = None, log_file: Optional[str] = 'agentforge'):
        """
        Initialize an Agent instance with necessary configurations and services.
        
        Args:
            agent_name: Name of the agent. Defaults to class name if not provided.
            log_file: Name of the log file. Defaults to 'agentforge'.
        """
        self.agent_name: str = agent_name if agent_name is not None else self.__class__.__name__
        self.logger: Logger = Logger(self.agent_name, log_file)
        
        # Initialize services
        self.config = Config()
        self.prompt_processor = PromptProcessor()
        
        # Initialize data attributes
        self.agent_data: Optional[Dict[str, Any]] = None
        self.persona: Optional[Dict[str, Any]] = None
        self.persona_settings: Optional[Dict[str, Any]] = None
        self.model: Optional[BaseModel] = None
        self.prompt_template: Optional[Dict[str, Any]] = None
        self.template_data: Dict[str, Any] = {}
        self.prompt: Optional[Dict[str]] = None
        self.result: Optional[str] = None
        self.output: Optional[str] = None
        self.images: List[str] = []
        
        # Load configuration
        self.initialize_agent_config()

    # ---------------------------------
    # Execution
    # ---------------------------------

    def run(self, **kwargs: Any) -> Optional[str]:
        """
        Execute the agent's workflow from data loading through output building.
        
        Args:
            **kwargs: Keyword arguments to incorporate into the agent's data.
            
        Returns:
            The output generated by the agent or None if execution failed.
        """
        try:
            self.logger.info(f"{self.agent_name} - Running...")
            
            self.load_data(**kwargs)
            self.process_data()
            self.render_prompt()
            self.run_model()
            self.parse_result()
            self.save_to_storage()
            self.build_output()
            
            self.logger.info(f"{self.agent_name} - Done!")
            return self.output
        except Exception as e:
            self.logger.error(f"Agent execution failed: {e}")
            return None

    # ---------------------------------
    # Configuration Loading
    # ---------------------------------

    def initialize_agent_config(self) -> None:
        """Load all agent configurations and resolve storage requirements."""
        self.load_agent_data()
        self.load_prompt_template()
        self.load_persona_data()
        self.load_model()
        self.resolve_storage()

    def load_agent_data(self) -> None:
        """Load and validate the agent's configuration data."""
        self.agent_data = self.config.load_agent_data(self.agent_name).copy()
        self.validate_agent_data()

    def load_prompt_template(self) -> None:
        """Load and validate prompt templates for the agent."""
        self.prompt_template = self.agent_data.get('prompts', {})
        
        if not self.prompt_template:
            error_msg = f"No prompts defined for agent '{self.agent_name}'."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

        self.prompt_processor.check_prompt_format(self.prompt_template)
        self.logger.debug(f"Prompts for '{self.agent_name}' validated.")

    def load_persona_data(self) -> None:
        """
        Load persona data if personas are enabled in system settings.
        Add persona data to template variables for prompt rendering.
        
        With v2 persona structure:
        1. Flatten static and retrieval sections
        2. Build persona_md for system prompt injection
        3. Process according to auto_inject_persona and other flags
        """
        personas_enabled = self.agent_data['settings']['system']['persona'].get('enabled', False)
        if not personas_enabled:
            return
            
        self.persona = self.agent_data.get('persona', {})
        self.validate_persona_data()
        self.logger.debug(f"Persona Data Loaded for '{self.agent_name}'.")
        
        if not self.persona:
            return
        
        # Get persona settings
        self.persona_settings = self.agent_data['settings']['system']['persona']
        
        # Process the persona data according to settings
        flattened_persona = self._flatten_persona()
        
        # Add flattened persona to template data for legacy placeholder support
        if self.persona_settings.get('allow_legacy_placeholders', True):
            self._add_legacy_placeholders(flattened_persona)
        
        # Build and add persona_md for system prompt injection
        if self.persona_settings.get('auto_inject_persona', True):
            self._build_persona_markdown()

    def _flatten_persona(self) -> Dict[str, Any]:
        """
        Flatten the persona structure for legacy placeholder support.
        Static sections override retrieval sections for duplicate keys.
        
        Returns:
            Dict[str, Any]: Flattened persona with lowercase keys
        """
        flattened_persona = {}
        
        # Process static section
        static_content = self.persona.get('static', {})
        for key, value in static_content.items():
            flattened_persona[key.lower()] = value
        
        # Process retrieval section 
        retrieval_content = self.persona.get('retrieval', {})
        for key, value in retrieval_content.items():
            # Don't override static keys
            if key.lower() not in flattened_persona:
                flattened_persona[key.lower()] = value
        
        # If no static/retrieval sections but has data, treat as legacy
        if not static_content and not retrieval_content and self.persona:
            flattened_persona = {k.lower(): v for k, v in self.persona.items()}
            
        return flattened_persona
        
    def _add_legacy_placeholders(self, flattened_persona: Dict[str, Any]) -> None:
        """
        Add flattened persona keys to template_data for legacy placeholder support.
        
        Args:
            flattened_persona (Dict[str, Any]): The flattened persona dictionary
        """
        for key, value in flattened_persona.items():
            self.template_data[key] = value
            
    def _build_persona_markdown(self) -> None:
        """
        Build markdown representation of static persona content for system prompt injection.
        Truncate if exceeds character cap from settings.
        """
        static_content = self.persona.get('static', {})
        if not static_content:
            return
            
        persona_md = self.prompt_processor.build_persona_markdown(static_content, self.persona_settings)
        if persona_md:
            # Store persona_md in template_data
            self.template_data['persona_md'] = persona_md

    def load_model(self) -> None:
        """Load and validate the model for the agent."""
        self.model = self.agent_data.get('model')
        
        if not self.model:
            error_msg = f"Model not specified for agent '{self.agent_name}'."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    def resolve_storage(self) -> None:
        """Configure storage for the agent if enabled in settings."""
        storage_enabled = self.agent_data['settings']['storage']['options'].get('enabled', False)
        
        if not storage_enabled:
            self.agent_data['storage'] = None

    # ---------------------------------
    # Validation
    # ---------------------------------

    def validate_agent_data(self) -> None:
        """Ensure agent data has all required keys and structure."""
        if not self.agent_data:
            error_msg = f"Agent data for '{self.agent_name}' is not loaded."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

        required_keys = ['params', 'prompts', 'settings']
        for key in required_keys:
            if key not in self.agent_data:
                error_msg = f"Agent data missing required key '{key}' for agent '{self.agent_name}'."
                self.logger.error(error_msg)
                raise ValueError(error_msg)

        if 'system' not in self.agent_data['settings']:
            error_msg = f"Agent data settings missing 'system' key for agent '{self.agent_name}'."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    def validate_persona_data(self) -> None:
        """Validate persona data if available."""
        if not self.persona:
            self.logger.warning(f"Personas are enabled but no persona data found for agent '{self.agent_name}'.")
        else:
            self.logger.debug(f"Persona for '{self.agent_name}' validated!")

    # ---------------------------------
    # Data Loading
    # ---------------------------------

    def load_data(self, **kwargs: Any) -> None:
        """
        Load all data needed for prompt generation, including dynamic updates.
        
        Args:
            **kwargs: Additional data to incorporate into template variables.
        """
        if self.agent_data['settings']['system']['misc'].get('on_the_fly', False):
            self.initialize_agent_config()

        self.load_from_storage()
        self.load_additional_data()
        self.template_data.update(kwargs)

    def load_from_storage(self) -> None:
        """
        Load data from configured storage.
        
        Override this method in subclasses to implement specific storage loading.
        """
        pass

    def load_additional_data(self) -> None:
        """
        Load custom additional data for the agent.
        
        Override this method in subclasses to load custom data.
        """
        pass

    # ---------------------------------
    # Processing
    # ---------------------------------

    def process_data(self) -> None:
        """
        Process loaded data before generating prompts.
        
        Override this method in subclasses to implement custom data processing.
        """
        pass

    def render_prompt(self) -> None:
        """Render prompt templates with the current template data and inject persona if available."""
        self.prompt = self.prompt_processor.render_prompts(self.prompt_template, self.template_data)
        self.prompt_processor.validate_rendered_prompts(self.prompt)
        
        # Check if we need to inject persona_md into system prompt
        self.prompt = self.prompt_processor.check_inject_persona_md(
            self.prompt, 
            self.template_data, 
            self.persona_settings
        )

    # ---------------------------------
    # Model Execution
    # ---------------------------------

    def run_model(self) -> None:
        """Execute the model with the rendered prompt and configured parameters."""
        if self.agent_data['settings']['system']['debug'].get('mode', False):
            self.result = self.agent_data['simulated_response']
            return

        params: Dict[str, Any] = self.agent_data.get("params", {})
        params['agent_name'] = self.agent_name
        
        if self.images:
            params['images'] = self.images
            
        self.result = self.model.generate(self.prompt, **params).strip()

    # ---------------------------------
    # Result Handling
    # ---------------------------------

    def parse_result(self) -> None:
        """
        Process model output as needed.
        
        Override this method in subclasses to implement custom result parsing.
        """
        pass

    def save_to_storage(self) -> None:
        """
        Save results to configured storage.
        
        Override this method in subclasses to implement custom storage saving.
        """
        pass

    def build_output(self) -> None:
        """
        Build the final output from model results.
        
        Override this method in subclasses to implement custom output formatting.
        By default, uses the raw model result as output.
        """
        self.output = self.result
